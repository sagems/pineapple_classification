{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2018/19 CeNAT Model"
      ],
      "metadata": {
        "id": "TMTUFj4phgMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Set-Up"
      ],
      "metadata": {
        "id": "-S3WxZoDGqxp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os4F4Dw1gVHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb70bf3-bdfb-4a38-c7e6-dda2baf30a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# mount drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scikit-learn original paper: https://jmlr.csail.mit.edu/papers/v12/pedregosa11a.html\n",
        "# Scikit-learn documentation: https://scikit-learn.org/stable/\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, \\\n",
        "                                    RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, \\\n",
        "                            classification_report, roc_curve, auc, \\\n",
        "                            roc_auc_score\n",
        "\n",
        "# Seaborn: https://seaborn.pydata.org/index.html\n",
        "# Scipy: https://docs.scipy.org/doc/scipy/\n",
        "# MatplotLib: https://matplotlib.org/stable/index.html\n",
        "# NumPy: https://numpy.org/doc/1.26/\n",
        "# Pandas:  https://pandas.pydata.org/docs/\n",
        "# GraphViz: https://graphviz.org/documentation/\n",
        "\n",
        "import seaborn as sns\n",
        "from scipy.stats import randint\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import graphviz\n",
        "\n",
        "# read and display data\n",
        "sms_filepath = '/content/drive/MyDrive/CS 131 final project/training_data/cleaned_combined.csv'\n",
        "hn_filepath = '/content/drive/MyDrive/cleaned_combined.csv'\n",
        "\n",
        "# specify your filepath!\n",
        "df = pd.read_csv(hn_filepath)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LGRsd99_lcWQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9c710572-8e7d-4d01-f33f-31e4e8031513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      B11       B2       B3       B4      B8      NDMI      NDVI      NDWI  \\\n",
              "0  0.3015  0.04380  0.07915  0.06085  0.3104  0.014545  0.672189 -0.593634   \n",
              "1  0.0415  0.00620  0.01450  0.00870  0.1038  0.428768  0.845333 -0.754861   \n",
              "2  0.0456  0.01260  0.01900  0.00950  0.1473  0.527216  0.878827 -0.771497   \n",
              "3  0.1271  0.02305  0.04530  0.02010  0.3301  0.444007  0.885208 -0.758657   \n",
              "4  0.4510  0.25540  0.30000  0.30240  0.4976  0.049125  0.244000 -0.247743   \n",
              "\n",
              "       SAVI  pineapple   latitude  longitude  year  \n",
              "0  0.429641          0   9.728799 -85.211897  2018  \n",
              "1  0.232898          0  10.017698 -83.274950  2018  \n",
              "2  0.314708          0   9.418162 -84.093854  2018  \n",
              "3  0.546930          0   9.882322 -83.724646  2018  \n",
              "4  0.225231          0  10.006289 -83.301630  2018  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fef0f95-0fb4-49e2-9096-824e696bf2dd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>B11</th>\n",
              "      <th>B2</th>\n",
              "      <th>B3</th>\n",
              "      <th>B4</th>\n",
              "      <th>B8</th>\n",
              "      <th>NDMI</th>\n",
              "      <th>NDVI</th>\n",
              "      <th>NDWI</th>\n",
              "      <th>SAVI</th>\n",
              "      <th>pineapple</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.3015</td>\n",
              "      <td>0.04380</td>\n",
              "      <td>0.07915</td>\n",
              "      <td>0.06085</td>\n",
              "      <td>0.3104</td>\n",
              "      <td>0.014545</td>\n",
              "      <td>0.672189</td>\n",
              "      <td>-0.593634</td>\n",
              "      <td>0.429641</td>\n",
              "      <td>0</td>\n",
              "      <td>9.728799</td>\n",
              "      <td>-85.211897</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0415</td>\n",
              "      <td>0.00620</td>\n",
              "      <td>0.01450</td>\n",
              "      <td>0.00870</td>\n",
              "      <td>0.1038</td>\n",
              "      <td>0.428768</td>\n",
              "      <td>0.845333</td>\n",
              "      <td>-0.754861</td>\n",
              "      <td>0.232898</td>\n",
              "      <td>0</td>\n",
              "      <td>10.017698</td>\n",
              "      <td>-83.274950</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0456</td>\n",
              "      <td>0.01260</td>\n",
              "      <td>0.01900</td>\n",
              "      <td>0.00950</td>\n",
              "      <td>0.1473</td>\n",
              "      <td>0.527216</td>\n",
              "      <td>0.878827</td>\n",
              "      <td>-0.771497</td>\n",
              "      <td>0.314708</td>\n",
              "      <td>0</td>\n",
              "      <td>9.418162</td>\n",
              "      <td>-84.093854</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.1271</td>\n",
              "      <td>0.02305</td>\n",
              "      <td>0.04530</td>\n",
              "      <td>0.02010</td>\n",
              "      <td>0.3301</td>\n",
              "      <td>0.444007</td>\n",
              "      <td>0.885208</td>\n",
              "      <td>-0.758657</td>\n",
              "      <td>0.546930</td>\n",
              "      <td>0</td>\n",
              "      <td>9.882322</td>\n",
              "      <td>-83.724646</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.4510</td>\n",
              "      <td>0.25540</td>\n",
              "      <td>0.30000</td>\n",
              "      <td>0.30240</td>\n",
              "      <td>0.4976</td>\n",
              "      <td>0.049125</td>\n",
              "      <td>0.244000</td>\n",
              "      <td>-0.247743</td>\n",
              "      <td>0.225231</td>\n",
              "      <td>0</td>\n",
              "      <td>10.006289</td>\n",
              "      <td>-83.301630</td>\n",
              "      <td>2018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fef0f95-0fb4-49e2-9096-824e696bf2dd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0fef0f95-0fb4-49e2-9096-824e696bf2dd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0fef0f95-0fb4-49e2-9096-824e696bf2dd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7ca63272-73c2-47c6-8b92-3386275aae26\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ca63272-73c2-47c6-8b92-3386275aae26')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7ca63272-73c2-47c6-8b92-3386275aae26 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10635,\n  \"fields\": [\n    {\n      \"column\": \"B11\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10616893671085431,\n        \"min\": 0.00655,\n        \"max\": 0.9508,\n        \"num_unique_values\": 5192,\n        \"samples\": [\n          0.03685,\n          0.2759,\n          0.26975\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1559810946052511,\n        \"min\": 0.0001,\n        \"max\": 1.3848,\n        \"num_unique_values\": 3470,\n        \"samples\": [\n          0.0399,\n          0.06815,\n          0.0974\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14681213032545729,\n        \"min\": 0.0011,\n        \"max\": 1.3416,\n        \"num_unique_values\": 3650,\n        \"samples\": [\n          0.0877,\n          0.3273,\n          0.0508\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14395911894325947,\n        \"min\": 0.0001,\n        \"max\": 1.3144,\n        \"num_unique_values\": 3872,\n        \"samples\": [\n          0.29445,\n          0.17905,\n          0.2767\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12498141301496273,\n        \"min\": 0.0149,\n        \"max\": 1.3336,\n        \"num_unique_values\": 4431,\n        \"samples\": [\n          0.1509,\n          0.201,\n          0.3759\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NDMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19681773620036289,\n        \"min\": -0.33805192,\n        \"max\": 0.76478976,\n        \"num_unique_values\": 10619,\n        \"samples\": [\n          0.41562366,\n          0.25398853,\n          0.06248658\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NDVI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25421817426874677,\n        \"min\": -0.5633188,\n        \"max\": 0.9972414,\n        \"num_unique_values\": 10593,\n        \"samples\": [\n          0.78532267,\n          0.6797171,\n          0.5970636\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NDWI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21881788428531004,\n        \"min\": -0.9772962,\n        \"max\": 0.6413959,\n        \"num_unique_values\": 10585,\n        \"samples\": [\n          -0.4374793,\n          -0.670202,\n          -0.060160685\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SAVI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.15648107729409386,\n        \"min\": -0.144275829172636,\n        \"max\": 0.7531343839372504,\n        \"num_unique_values\": 10624,\n        \"samples\": [\n          0.5263126090794008,\n          0.1530342882996624,\n          0.4627549776267626\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pineapple\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6724305238263585,\n        \"min\": 8.05317194331048,\n        \"max\": 11.199700888995928,\n        \"num_unique_values\": 5856,\n        \"samples\": [\n          9.284313040196285,\n          10.409363102027571\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7419788219838944,\n        \"min\": -85.86596050597073,\n        \"max\": -82.60884894881016,\n        \"num_unique_values\": 6159,\n        \"samples\": [\n          -83.94078102057418,\n          -84.2356080968222\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2018,\n        \"max\": 2019,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2019,\n          2018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collect Data\n",
        "bands, features, coordinates"
      ],
      "metadata": {
        "id": "w0TnT0V8mpiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get basic bands data\n",
        "bands = [col for col in df.columns if col.startswith('B')]\n",
        "X_bands = df[bands].to_numpy()\n",
        "\n",
        "# get feature data\n",
        "feats = ['NDMI', 'NDVI', 'NDWI', 'SAVI']\n",
        "X_feats = df[feats].to_numpy()\n",
        "\n",
        "# get coords data\n",
        "coords = ['latitude', 'longitude']\n",
        "X_coords = df[coords].to_numpy()\n",
        "\n",
        "# combined data\n",
        "X = np.hstack((X_bands, X_feats))\n",
        "\n",
        "# get test data\n",
        "y = df['pineapple'].to_numpy()"
      ],
      "metadata": {
        "id": "WZ5YTJEYjA6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Util Functions"
      ],
      "metadata": {
        "id": "6rDpYgxdtoE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Analyze classifier predictions using confusion matrix, bar graph,\n",
        "and ROC curve, and print out evaluation metrics.\n",
        "\n",
        "Args:\n",
        "    y_test: test data labels\n",
        "    y_pred: predicted labels\n",
        "    y_scores: probabilities for predicted labels\n",
        "\"\"\"\n",
        "def analyze_results(y_test, y_pred, y_scores):\n",
        "  # print classification report\n",
        "  print(classification_report(y_test, y_pred, digits=6))\n",
        "\n",
        "  # plot analytics graphs\n",
        "  plt_confusion_matrix(y_test, y_pred)\n",
        "  plt_bar_graph(y_test, y_pred)\n",
        "  plt_ROC_curve(y_test, y_scores)\n",
        "\n",
        "\n",
        "def plt_confusion_matrix(y_true, y_pred):\n",
        "  # confusion matrix\n",
        "  conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "  labels = set(['Non-pineapple', 'Pineapple'])\n",
        "\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Reds', xticklabels=sorted(labels), yticklabels=sorted(labels))\n",
        "  plt.xlabel('Predicted labels')\n",
        "  plt.ylabel('True labels')\n",
        "  plt.title('Confusion Matrix')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plt_bar_graph(y_true, y_pred):\n",
        "  # set up bar graph\n",
        "  unique, counts_true = np.unique(y_true, return_counts=True)\n",
        "  unique, counts_pred = np.unique(y_pred, return_counts=True)\n",
        "\n",
        "  x = np.arange(len(unique))  # the label locations\n",
        "  width = 0.3                 # the width of the bars\n",
        "  labels = set(['Non-pineapple', 'Pineapple'])\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  rects1 = ax.bar(x - width/2, counts_true, width, label='True', color='#279989')\n",
        "  rects2 = ax.bar(x + width/2, counts_pred, width, label='Predicted', color='#8C1515')\n",
        "\n",
        "  # plot bar graph\n",
        "  ax.set_ylabel('Counts')\n",
        "  ax.set_title('Counts by Class and Type')\n",
        "  ax.set_xticks(x)\n",
        "  ax.set_xticklabels(labels)\n",
        "  ax.legend()\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plt_ROC_curve(y_test, y_scores):\n",
        "  # plot ROC curve\n",
        "  fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(fpr, tpr, color='#8C1515',\n",
        "          lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "  plt.plot([0, 1], [0, 1], color='#279989', lw=2, linestyle='--')\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.0])\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('ROC Curve')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "GpGpi8rVuxlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Models"
      ],
      "metadata": {
        "id": "o6c1wjyPtP0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree, Random Forest, Gradient Boosting"
      ],
      "metadata": {
        "id": "gWR1gDr6m4w5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tune Hyperparameters"
      ],
      "metadata": {
        "id": "1wa24NTnX5Yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Return random hyperparameter distribution across pre-set ranges for\n",
        "specified classifier.\n",
        "\n",
        "Args:\n",
        "    Classifier: decision tree estimator being considered\n",
        "\n",
        "Returns:\n",
        "  param_dist: distribution of parameters to test\n",
        "\"\"\"\n",
        "def tune_hyperparams(Classifier):\n",
        "  param_dist = {}\n",
        "\n",
        "  if Classifier == DecisionTreeClassifier:\n",
        "    param_dist = {'max_depth': randint(1,20),\n",
        "                  'min_samples_split': randint(2, 20),\n",
        "                  'min_samples_leaf': randint(1, 20),}\n",
        "  elif Classifier == RandomForestClassifier:\n",
        "    param_dist = {'n_estimators': randint(50, 500),\n",
        "                  'max_depth': randint(1, 20),\n",
        "                  'min_samples_split': randint(2, 20),\n",
        "                  'min_samples_leaf': randint(1, 20),\n",
        "                  'max_features': ['sqrt', 'log2', None]}\n",
        "  elif Classifier == GradientBoostingClassifier:\n",
        "    param_dist = {'n_estimators': randint(50, 500),\n",
        "                  'max_depth': randint(1, 20),\n",
        "                  'learning_rate': [0.01, 0.1, 0.2, 0.3]}\n",
        "\n",
        "  return param_dist"
      ],
      "metadata": {
        "id": "of9kft0iwrQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Get tuned classifier with hard-coded parameters.\n",
        "\n",
        "Args:\n",
        "    Classifier: decision tree estimator being considered\n",
        "    depth: max-depth for tree model\n",
        "\n",
        "Returns:\n",
        "  TunedClassifier: tuned classifier ready to be fit to data\n",
        "\"\"\"\n",
        "def get_tuned_classifier(Classifier, depth):\n",
        "  if Classifier == DecisionTreeClassifier:\n",
        "    TunedClassifier = DecisionTreeClassifier(max_depth=depth,\n",
        "                                             min_samples_split=11,\n",
        "                                             min_samples_leaf=2,\n",
        "                                             random_state=0)\n",
        "\n",
        "  elif Classifier == RandomForestClassifier:\n",
        "    TunedClassifier = RandomForestClassifier(max_depth=depth,\n",
        "                                             max_features='log2',\n",
        "                                             min_samples_leaf=10,\n",
        "                                             min_samples_split=6,\n",
        "                                             n_estimators=434,\n",
        "                                             random_state=0)\n",
        "\n",
        "  elif Classifier == GradientBoostingClassifier:\n",
        "    TunedClassifier = GradientBoostingClassifier(max_depth=depth,\n",
        "                                                 learning_rate=0.2,\n",
        "                                                 n_estimators=458,\n",
        "                                                 random_state=0)\n",
        "\n",
        "  return TunedClassifier"
      ],
      "metadata": {
        "id": "DF2VtcpLDrZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Find best depth to fit decision tree to.\n",
        "\n",
        "Args:\n",
        "    X: feature data\n",
        "    y: datapoint labels\n",
        "    Classifier: decision tree estimator being considered\n",
        "\n",
        "Returns:\n",
        "    best_depth: depth of decision tree classifier that maximizes accuracy\n",
        "\"\"\"\n",
        "def tune_max_depth(X, y, Classifier):\n",
        "  # tune max-depth parameter\n",
        "  max_depths = range(1, 21)\n",
        "  cv_scores = []\n",
        "\n",
        "  # train/test over possible depths\n",
        "  for depth in max_depths:\n",
        "      # clf = get_tuned_classifier(Classifier, depth)\n",
        "      clf = Classifier(max_depth=depth, random_state=0)\n",
        "      clf.fit(X, y)\n",
        "      scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
        "      cv_scores.append(np.mean(scores))\n",
        "\n",
        "  # plot performance across depths\n",
        "  plot_depth_tune(max_depths, cv_scores)\n",
        "\n",
        "  # find best depth\n",
        "  best_depth = max_depths[np.argmax(cv_scores)]\n",
        "  print(f\"\\nBest max depth: {best_depth}\")\n",
        "\n",
        "  return best_depth\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Plot performance across range of possible DT depths.\n",
        "\n",
        "Args:\n",
        "    max_depths: range of maximum depths considered\n",
        "    cv_scores: cross validation scores (accuracies)\n",
        "\"\"\"\n",
        "def plot_depth_tune(max_depths, cv_scores):\n",
        "  # plot performance across depths\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.plot(max_depths, cv_scores, marker='o', color='#8C1515')\n",
        "  plt.xlabel('Max Depth')\n",
        "  plt.ylabel('Average Cross-Validation Score')\n",
        "  plt.title('Classifier Performance at Different Max Depths')\n",
        "  plt.grid(True)\n",
        "  plt.xticks(max_depths)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "SLw6doK_p8Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and Test Classifiers"
      ],
      "metadata": {
        "id": "UnK35hhQX-mL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Build, train, amd test classifier derived from best model produced by\n",
        "Randomized Search Cross Validation for tuning various hyperparameters.\n",
        "\n",
        "Args:\n",
        "    X: feature data\n",
        "    y: datapoint labels\n",
        "    Classifier: decision tree estimator being considered\n",
        "\n",
        "Returns:\n",
        "    y_test: test data labels\n",
        "    y_pred: predicted labels\n",
        "    y_scores: probabilities for predicted labels\n",
        "\"\"\"\n",
        "def decision_tree_classifier_param_tuning(X, y, Classifier):\n",
        "  # 80-20 split data into train and test sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "  # tune hyperparameters and build classifier\n",
        "  param_dist = tune_hyperparams(Classifier)\n",
        "  dt = RandomizedSearchCV(Classifier(),\n",
        "                          param_distributions = param_dist,\n",
        "                          n_iter=10,\n",
        "                          cv=10,\n",
        "                          scoring='accuracy',\n",
        "                          random_state=0)\n",
        "\n",
        "  # fit classifier to data\n",
        "  dt.fit(X_train, y_train)\n",
        "\n",
        "  # best parameter set\n",
        "  print(\"Best parameters found: \", dt.best_params_)\n",
        "  print(\"Best accuracy found: \", dt.best_score_)\n",
        "  best_dt = dt.best_estimator_\n",
        "\n",
        "  # get probability of data point being pineapple\n",
        "  y_scores = best_dt.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  # predict labels of test set\n",
        "  y_pred = best_dt.predict(X_test)\n",
        "\n",
        "  # display accuracy of classifier\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  # print(f\"\\nAccuracy with max depth of {best_depth}: {accuracy}\\n\")\n",
        "  print(f\"\\nAccuracy: {accuracy}\\n\")\n",
        "\n",
        "  return y_test, y_pred, y_scores"
      ],
      "metadata": {
        "id": "LDzjYyCbC6lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Build, train, amd test classifier derived from best model produced by\n",
        "tuning max-depth parameter alone.\n",
        "\n",
        "Args:\n",
        "    X: feature data\n",
        "    y: datapoint labels\n",
        "    Classifier: decision tree estimator being considered\n",
        "\n",
        "Returns:\n",
        "    y_test: test data labels\n",
        "    y_pred: predicted labels\n",
        "    y_scores: probabilities for predicted labels\n",
        "\"\"\"\n",
        "def decision_tree_classifier_max_depth(X, y, Classifier):\n",
        "  # 80-20 split data into train and test sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "  # find best depth and build classifier\n",
        "  best_depth = tune_max_depth(X, y, Classifier)\n",
        "  dt = get_tuned_classifier(Classifier, best_depth)\n",
        "\n",
        "  # fit classifier to data\n",
        "  dt.fit(X_train, y_train)\n",
        "\n",
        "  # get probability of data point being pineapple\n",
        "  y_scores = dt.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  # predict labels of test set\n",
        "  y_pred = dt.predict(X_test)\n",
        "\n",
        "  # display accuracy of classifier\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  # print(f\"\\nAccuracy with max depth of {best_depth}: {accuracy}\\n\")\n",
        "  print(f\"\\nAccuracy: {accuracy}\\n\")\n",
        "\n",
        "  return y_test, y_pred, y_scores"
      ],
      "metadata": {
        "id": "bPlTsTDkXb4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Runtimes on Complete Data (Max-Depth)**\n",
        "- Decision Tree: 12s, max-depth of 10 for 85.3% accuracy\n",
        "- Random Forest: 4m18s, max-depth of 19 for 87.9% accuracy\n",
        "- Gradient Boosting: 21m6s, max-depth of 7 for 87.5% accuracy\n",
        "\n",
        "**Runtimes on Complete Data (Generalized Tuning)**\n",
        "- Decision Tree: 7s, 86.2% accuracy\n",
        "  - best parameters found:  {'max_depth': 10, 'min_samples_leaf': 11, 'min_samples_split': 2}\n",
        "- Random Forest: 12m22s, 88.1% accuracy\n",
        "  - best parameters found:  {'max_depth': 15, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 6, 'n_estimators': 434}\n",
        "- Gradient Boosting: 45m44s, 87.35308% accuracy\n",
        "  - best parameters found:  {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 458}\n"
      ],
      "metadata": {
        "id": "x7IDj7NLaqHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sklearn_classifiers = {\"Decision Tree\": DecisionTreeClassifier,\n",
        "                       \"Random Forest\": RandomForestClassifier,\n",
        "                       \"Gradient Boosting\": GradientBoostingClassifier}\n",
        "\n",
        "# change this to change model type!\n",
        "classifier_type = \"Decision Tree\"\n",
        "Classifier = sklearn_classifiers[classifier_type]\n",
        "\n",
        "# print(\"\\n\\n====================================================\")\n",
        "# print(f\"Running {classifier_type} classifier on bands data...\")\n",
        "# print(\"====================================================\\n\")\n",
        "# bands_test, bands_pred, bands_scores = decision_tree_classifier_param_tuning(X_bands, y, Classifier)\n",
        "# bands_test, bands_pred, bands_scores = decision_tree_classifier_max_depth(X_bands, y, Classifier)\n",
        "\n",
        "# print(\"\\n\\n====================================================\")\n",
        "# print(f\"Running {classifier_type} classifier on features data...\")\n",
        "# print(\"====================================================\\n\")\n",
        "# feats_test, feats_pred, feats_scores = decision_tree_classifier_param_tuning(X_feats, y, Classifier)\n",
        "# feats_test, feats_pred, feats_scores = decision_tree_classifier_max_depth(X_feats, y, Classifier)\n",
        "\n",
        "print(\"\\n\\n====================================================\")\n",
        "print(f\"Running {classifier_type} classifier on complete data...\")\n",
        "print(\"====================================================\\n\")\n",
        "# complete_test, complete_pred, complete_scores = decision_tree_classifier_param_tuning(X, y, Classifier)\n",
        "complete_test, complete_pred, complete_scores = decision_tree_classifier_max_depth(X, y, Classifier)"
      ],
      "metadata": {
        "id": "vitl8aytYDQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Results"
      ],
      "metadata": {
        "id": "8XOEybxGZS6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# analyze_results(bands_test, bands_pred, bands_scores)\n",
        "# analyze_results(feats_test, feats_pred, feats_scores)\n",
        "\n",
        "print(\"\\n\\n====================================================\")\n",
        "print(f\"Analyzing {classifier_type} classifier on complete data...\")\n",
        "print(\"====================================================\\n\")\n",
        "analyze_results(complete_test, complete_pred, complete_scores)"
      ],
      "metadata": {
        "id": "ocaG9Hi0ZRZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-Decision Tree Models"
      ],
      "metadata": {
        "id": "x6MNr0_6jz7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression, K-Nearest Neighbors"
      ],
      "metadata": {
        "id": "MgpWjhrZnCjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and Classify Classifiers"
      ],
      "metadata": {
        "id": "BsMiYqLHmnTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Build, train, and test non-tree based classifier (either KNN or\n",
        "Logistic Regression).\n",
        "\n",
        "Args:\n",
        "    X: feature data\n",
        "    y: datapoint labels\n",
        "    Classifier: decision tree estimator being considered\n",
        "\n",
        "Returns:\n",
        "    y_test: test data labels\n",
        "    y_pred: predicted labels\n",
        "    y_scores: probabilities for predicted labels\n",
        "\"\"\"\n",
        "def non_decision_tree_classifier(X, y, Classifier):\n",
        "  # 80-20 split data into train and test sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "  # create a logistic regression classifier at best depth\n",
        "  ndt = Classifier()\n",
        "\n",
        "  # fit classifier to data\n",
        "  ndt.fit(X_train, y_train)\n",
        "\n",
        "  # get probability of data point being pineapple\n",
        "  y_scores = ndt.predict_proba(X_test)[:, 1]\n",
        "\n",
        "  # predict labels of test set\n",
        "  y_pred = ndt.predict(X_test)\n",
        "\n",
        "  # display accuracy of classifier\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(f\"\\nAccuracy: {accuracy}\\n\")\n",
        "\n",
        "  return y_test, y_pred, y_scores"
      ],
      "metadata": {
        "id": "hEKhVqaQmWbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Performance on Complete Data**\n",
        "\n",
        "- Logistic Regression: 0s, 86.69488% accuracy\n",
        "- K-Nearest Neighbors: 0s, 86.60085% accuracy"
      ],
      "metadata": {
        "id": "5eQOftJGD1gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sklearn_classifiers = {\"Logistic Regression\": LogisticRegression,\n",
        "                       \"K-Nearest Neighbors\": KNeighborsClassifier}\n",
        "\n",
        "# change this to change model type!\n",
        "classifier_type = \"Logistic Regression\"\n",
        "Classifier = sklearn_classifiers[classifier_type]\n",
        "\n",
        "# print(\"\\n\\n====================================================\")\n",
        "# print(f\"Running {classifier_type} classifier on bands data...\")\n",
        "# print(\"====================================================\\n\")\n",
        "# bands_test, bands_pred, bands_scores = non_decision_tree_classifier(X_bands, y, Classifier)\n",
        "\n",
        "# print(\"\\n\\n====================================================\")\n",
        "# print(f\"Running {classifier_type} classifier on features data...\")\n",
        "# print(\"====================================================\\n\")\n",
        "# feats_test, feats_pred, feats_scores = non_decision_tree_classifier(X_feats, y, Classifier)\n",
        "\n",
        "print(\"\\n\\n====================================================\")\n",
        "print(f\"Running {classifier_type} classifier on complete data...\")\n",
        "print(\"====================================================\\n\")\n",
        "complete_test, complete_pred, complete_scores = non_decision_tree_classifier(X, y, Classifier)"
      ],
      "metadata": {
        "id": "XlXbeYoxmW1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Results"
      ],
      "metadata": {
        "id": "9qhvHhWfmk_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# analyze_results(bands_test, bands_pred, bands_scores)\n",
        "# analyze_results(feats_test, feats_pred, feats_scores)\n",
        "\n",
        "print(\"\\n\\n====================================================\")\n",
        "print(f\"Analyzing {classifier_type} classifier on complete data...\")\n",
        "print(\"====================================================\\n\")\n",
        "analyze_results(complete_test, complete_pred, complete_scores)"
      ],
      "metadata": {
        "id": "_48rA-L1mXGM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}